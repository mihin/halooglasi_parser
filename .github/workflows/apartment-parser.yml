name: HaloOglasi Apartment Parser

on:
  schedule:
    # Run at 7:00 AM, 1:00 PM, and 7:00 PM UTC
    # This corresponds to the new schedule requirements
    - cron: '0 7,13,19 * * *'
  
  # Allow manual triggering
  workflow_dispatch:

jobs:
  parse-apartments:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data and logs directories
      run: |
        mkdir -p data logs
    
    - name: Download previous apartment tracking data
      run: |
        echo "🔍 Looking for previous tracking data from last successful run..."
        
        # Get the last successful workflow run ID
        LAST_RUN_ID=$(gh run list --workflow=apartment-parser.yml --status=success --limit=1 --json databaseId --jq '.[0].databaseId' 2>/dev/null || echo "")
        
        if [ -n "$LAST_RUN_ID" ] && [ "$LAST_RUN_ID" != "null" ]; then
          echo "📥 Attempting to download from run ID: $LAST_RUN_ID"
          if gh run download $LAST_RUN_ID --name apartment-tracking-data --dir data/ 2>/dev/null; then
            echo "✅ Previous tracking data downloaded successfully"
          else
            echo "⚠️ Download failed, will create new tracking file"
          fi
        else
          echo "📝 No previous successful runs found (normal for first run)"
        fi
      env:
        GH_TOKEN: ${{ github.token }}
      continue-on-error: true
    
    - name: Initialize tracking file if needed
      run: |
        if [ ! -f "data/previous_apartment_ids.json" ]; then
          echo "📝 No previous tracking data (normal for first run)"
          echo "Creating new tracking file - all apartments will be marked as NEW"
          echo '[]' > data/previous_apartment_ids.json
        else
          echo "✅ Previous tracking data loaded successfully"
          echo "Will identify NEW vs EXISTING apartments"
        fi
    
    - name: Run apartment parser
      env:
        TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
        TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
      run: |
        cd scripts
        python run_search.py
    
    - name: Ensure tracking file exists before upload
      if: always()
      run: |
        if [ ! -f "data/previous_apartment_ids.json" ]; then
          echo "⚠️ Tracking file missing, creating empty one"
          echo '[]' > data/previous_apartment_ids.json
        fi
        echo "📁 Tracking file ready for upload"
    
    - name: Upload apartment tracking data for next run
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: apartment-tracking-data
        path: data/previous_apartment_ids.json
        retention-days: 90
    
    - name: Clean up output files
      if: always()
      run: |
        # Remove all generated files except previous_apartment_ids.json
        rm -f data/halooglasi_data.json
        rm -f data/halooglasi_data.xlsx
        rm -f logs/*.log
        echo "🧹 Cleaned up temporary output files" 